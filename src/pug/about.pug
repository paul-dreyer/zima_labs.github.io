html(lang="en")
    head
        meta(charset="utf-8")
        meta(name="viewport", content="width=device-width, initial-scale=1, shrink-to-fit=no")
        link(rel="preconnect", href="https://fonts.gstatic.com")
        link(href="https://fonts.googleapis.com/css2?family=Playfair+Display&display=swap", rel="stylesheet")
        link(href="https://api.fontshare.com/v2/css?f[]=clash-grotesk@400,300,500&display=swap", rel="stylesheet")
        link(rel="stylesheet", href="css/tailwind/tailwind.min.css")
        link(rel="icon", type="image/png", sizes="32x32", href="fav-icon.png")
        script(src="https://cdn.jsdelivr.net/npm/alpinejs@3.13.3/dist/cdn.min.js", defer="defer")
    
    body(class="antialiased bg-body text-body font-body")
        div(class="")
            section(x-data="{ mobileNavOpen: false }", class="relative overflow-hidden")
                div(class="container px-4 mx-auto")
                    div(class="flex items-center justify-between pt-6 -m-2")
                        div(class="w-auto p-2")
                            div(class="flex flex-wrap items-center")
                                div(class="w-auto")
                                    a(class="relative z-10 inline-block", href="index.html")
                                        img(src="images/logo-transparent.png", style="max-height: 60px;" alt="", class="")
                        div(class="w-auto p-2")
                            div(class="flex flex-wrap items-center")
                                div(class="w-auto hidden lg:block")
                                    ul(class="flex items-center mr-12")
                                        li(class="mr-12 text-white font-medium hover:text-green-400 tracking-tighter")
                                            a(href="index.html") Home
                                        li(class="mr-12 text-white font-medium hover:text-green-400 tracking-tighter")
                                            a(href="about.html") About
                                        li(class="mr-12 text-white font-medium hover:text-green-400 tracking-tighter")
                                            a(href="gallery.html") Data Gallery
                                        li(class="text-gray-600 font-medium tracking-tighter")
                                            a(href="#") Documentation
                                div(class="w-auto hidden lg:block")
                                    div(class="inline-block")
                                        a(class="inline-block px-8 py-4 text-black hover:text-white tracking-tighter bg-green-400 hover:bg-green-400 border-2 border-white focus:border-green-400 focus:border-opacity-40 focus:ring-4 focus:ring-green-400 focus:ring-opacity-40 rounded-full", href="contact.html") Contact
                                div(class="w-auto lg:hidden")
                                    button(x-on:click="mobileNavOpen = !mobileNavOpen", class="relative z-10 inline-block")
                                        svg(class="text-green-500", width="51", height="51", viewbox="0 0 56 56", fill="none", xmlns="http://www.w3.org/2000/svg")
                                            rect(width="56", height="56", rx="28", fill="currentColor")
                                            path(d="M37 32H19M37 24H19", stroke="black", stroke-width="1.5", stroke-linecap="round", stroke-linejoin="round")
                div(:class="{'block': mobileNavOpen, 'hidden': !mobileNavOpen}", class="hidden fixed top-0 left-0 bottom-0 w-4/6 sm:max-w-xs z-50")
                    div(x-on:click="mobileNavOpen = !mobileNavOpen", class="fixed inset-0 bg-black opacity-60")
                    nav(class="relative z-10 px-9 pt-8 h-full bg-black overflow-y-auto")
                        div(class="flex flex-wrap justify-between h-full")
                            div(class="w-full")
                                div(class="flex items-center justify-between -m-2")
                                    div(class="w-auto p-2")
                                        a(class="inline-block", href="#")
                                            img(src="images/logo-transparent.png", style="max-height: 150px;" alt="")
                                    div(class="w-auto p-2")
                                        button(x-on:click="mobileNavOpen = !mobileNavOpen", class="inline-block text-white")
                                            svg(width="24", height="24", viewbox="0 0 24 24", fill="none", xmlns="http://www.w3.org/2000/svg")
                                                path(d="M6 18L18 6M6 6L18 18", stroke="currentColor", stroke-width="2", stroke-linecap="round", stroke-linejoin="round")
                            div(class="flex flex-col justify-center py-16 w-full")
                                ul
                                    li(class="mb-8 text-white font-medium hover:text-opacity-90 tracking-tighter")
                                        a(href="index.html") Home
                                    li(class="mb-8 text-white font-medium hover:text-opacity-90 tracking-tighter")
                                        a(href="about.html") About
                                    li(class="mb-8 text-white font-medium hover:text-opacity-90 tracking-tighter")
                                        a(href="gallery.html") Data Gallery
                                    li(class="text-gray-600 font-medium tracking-tighter")
                                        a(href="#") Documentation
                            div(class="flex flex-col justify-end w-full pb-8")
                                a(class="inline-block px-8 py-4 text-center text-black hover:text-white tracking-tighter bg-green-400 hover:bg-green-400 border-2 border-white focus:border-green-400 focus:border-opacity-40 focus:ring-4 focus:ring-green-400 focus:ring-opacity-40 rounded-full", href="contact.html") Contact
           
            section(class="py-20 overflow-hidden")
                div(class="container px-4 mb-20 mx-auto")

                    div(class="md:max-w-xl text-center mx-auto mb-10")
                        h2(class="font-heading text-7xl text-white tracking-tighter-xl") About Synthetic Data
                    div(class="max-w-5xl mx-auto")
                        div(class="flex flex-wrap items-center justify-center mx-auto")
                            div(class="w-full md:w-3/4 px-4 lg:px-12")
                                h2(class="font-heading text-3xl text-green-300 tracking-tighter-xl mb-2") Curriculum Learning
                                p(class="mb-10 text-white") 
                                    | When we train policies control walking robots, we never start 
                                    | by asking the model to move the robot up a flight of steps, or 
                                    | traverse rough terrain. We start with a simple goal, and 
                                    | we gradually increase the difficulty of the tasks we ask the 
                                    | model to learn. This is called "curriculum learning", and it's
                                    | standard practice across almost every deep learning based
                                    | policy in robotics, but it's completely overlooked in training
                                    | computer vision models. This is largely due to the challenge
                                    | of representing how 'difficult' a particular image is to
                                    | ask the model to inference on. We're changing that. Every
                                    | image-label pair we create comes with a meta data file, that
                                    | describes a ton of information about the corresponding image
                                    | instance. Want to just train your model with images that have 
                                    | less than 5% occlusion for the first milestone, and gradually 
                                    | introduce images where the % of object occlusion rises? Done. 
                                    | Want to start with images where key objects only appear within 
                                    | some smaller region of the image, or exist within certain
                                    | distance bounds from the camera? Done.


                    div(class="max-w-5xl mx-auto")
                        div(class="flex flex-wrap items-center justify-center mx-auto")
                            div(class="w-full md:w-3/4 px-4 lg:px-12")
                                h2(class="font-heading text-3xl text-green-300 tracking-tighter-xl mb-2") Related Papers

                            //- Paper Block
                            div(x-data="{ expanded: false }", class="w-full md:w-3/4 px-4 lg:px-12")
                                h2(class="font-heading text-2xl text-white tracking-tighter-xl")
                                    | Synthetic Image Data for Deep Learning

                                //- Collapsible paragraph
                                p(
                                    :class="expanded ? 'text-gray-400' : 'text-gray-400 line-clamp-1'",
                                    class="transition-all duration-300"
                                )
                                    | Abstract—Realistic synthetic image data rendered from 3D
                                    | models can be used to augment image sets and train image
                                    | classification semantic segmentation models. In this work, we
                                    | explore how high quality physically-based rendering and domain
                                    | randomization can efficiently create a large synthetic dataset
                                    | based on production 3D CAD models of a real vehicle. We use this
                                    | dataset to quantify the effectiveness of synthetic augmentation
                                    | using U-net and Double-U-net models. We found that, for
                                    | this domain, synthetic images were an effective technique for
                                    | augmenting limited sets of real training data. We observed that
                                    | models trained on purely synthetic images had a very low mean
                                    | prediction IoU on real validation images. We also observed that
                                    | adding even very small amounts of real images to a synthetic
                                    | dataset greatly improved accuracy, and that models trained on
                                    | datasets augmented with synthetic images were more accurate
                                    | than those trained on real images alone.
                                    | Finally, we found that in use cases that benefit from incremen-
                                    | tal training or model specialization, pretraining a base model on
                                    | synthetic images provided a sizeable reduction in the training cost
                                    | of transfer learning, allowing up to 90% of the model training
                                    | to be front-loaded.

                                //- Toggle arrow
                                button(
                                    @click="expanded = !expanded"
                                    class="text-green-400 text-sm font-medium flex items-center space-x-1 hover:underline focus:outline-none"
                                )
                                    span(x-text="expanded ? 'Show less' : 'Show more'")
                                    svg(:class="expanded ? 'rotate-180' : ''", class="w-4 h-4 transform transition-transform duration-300", fill="none", stroke="currentColor", viewBox="0 0 24 24", xmlns="http://www.w3.org/2000/svg")
                                    path(stroke-linecap="round", stroke-linejoin="round", stroke-width="2", d="M19 9l-7 7-7-7")

                                button.view-paper-button(
                                    data-paper-id="paper1",
                                    class="mt-4 mb-8 inline-block px-6 py-2 text-white bg-green-500 hover:bg-green-600 rounded-lg text-sm"
                                ) View Paper

                            
                            //- Paper Block
                            div(x-data="{ expanded: false }", class="w-full md:w-3/4 px-4 lg:px-12")
                                h2(class="font-heading text-2xl text-white tracking-tighter-xl")
                                    | Domain randomization for transferring deep neural networks from simulation to the real world

                                //- Collapsible paragraph
                                p(
                                    :class="expanded ? 'text-gray-400' : 'text-gray-400 line-clamp-1'",
                                    class="transition-all duration-300"
                                )
                                    | Abstract—Bridging the ‘reality gap’ that separates simulated robotics from experiments on hardware could accelerate robotic
                                    | research through improved data availability. This paper ex- plores domain randomization, a simple technique for training
                                    | models on simulated images that transfer to real images by ran- domizing rendering in the simulator. With enough variability in
                                    | the simulator, the real world may appear to the model as just another variation. We focus on the task of object localization,
                                    | which is a stepping stone to general robotic manipulation skills. We find that it is possible to train a real-world object
                                    | detector that is accurate to 1.5 cm and robust to distractors and partial occlusions using only data from a simulator with
                                    | non-realistic random textures. To demonstrate the capabilities of our detectors, we show they can be used to perform grasping
                                    | in a cluttered environment. To our knowledge, this is the first successful transfer of a deep neural network trained only on
                                    | simulated RGB images (without pre-training on real images) to the real world for the purpose of robotic control.

                                //- Toggle arrow
                                button(
                                    @click="expanded = !expanded"
                                    class="text-green-400 text-sm font-medium flex items-center space-x-1 hover:underline focus:outline-none"
                                )
                                    span(x-text="expanded ? 'Show less' : 'Show more'")
                                    svg(:class="expanded ? 'rotate-180' : ''", class="w-4 h-4 transform transition-transform duration-300", fill="none", stroke="currentColor", viewBox="0 0 24 24", xmlns="http://www.w3.org/2000/svg")
                                    path(stroke-linecap="round", stroke-linejoin="round", stroke-width="2", d="M19 9l-7 7-7-7")

                                button.view-paper-button(
                                    data-paper-id="paper2",
                                    class="mt-4 mb-8 inline-block px-6 py-2 text-white bg-green-500 hover:bg-green-600 rounded-lg text-sm"
                                ) View Paper

                        
                    div(class="md:max-w-xl text-center mx-auto mb-10 mt-20")
                        h2(class="font-heading text-7xl text-white tracking-tighter-xl") About us
                    div(class="max-w-5xl mx-auto mb-10")
                        div(class="flex flex-wrap items-center justify-center mx-auto")
                            div(class="w-full md:w-3/4 px-4 lg:px-12")
                                p(class="mb-4 text-white") 
                                    | Our team comes from backgrounds of robotics, mechanical 
                                    | engineering, and manufacturing. We ran
                                    | into the same issue over and over again - we
                                    | have the AI and RL tools that can accomplish the job, whether
                                    | it's inspection, object detection, path identification etc.,
                                    | but open source datasets rarely met our needs for training to
                                    | accomplish custom tasks, and collecting and labeling real
                                    | world data is insanely painful and time consuming. So we set
                                    | out to build a compute pipe that can deliver as much data 
                                    | as necessary, in any context necessary. 
                                
            
            //- Page bottom
            section(class="bg-gray-50 overflow-hidden")
                div(class="py-14 bg-body rounded-b-5xl")
                div(class="py-12")
                    div(class="container px-4 mx-auto")
                        div(class="flex flex-wrap justify-center -m-8 mb-28")
                            div(class="w-full md:w-1/2 lg:w-4/12 p-8")
                                div(class="flex flex-col md:max-w-md items-center")
                                    img(class="mb-7", src="images/logo-dark-transparent.png", alt="")
                                    p(class="text-gray-400 font-medium") Take your computer vision capabilities to new heights
                            div(class="w-full md:w-1/2 lg:w-2/12 p-8")
                                //- h3(class="mb-6 text-lg text-black font-medium") Company
                                ul
                                    li(class="mb-2.5")
                                        a(class="inline-block text-lg font-medium text-gray-500 hover:text-black transition duration-300", href="index.html") Home
                                    li(class="mb-2.5")
                                        a(class="inline-block text-lg font-medium text-gray-500 hover:text-black transition duration-300", href="about.html") About
                                    li(class="mb-2.5")
                                        a(class="inline-block text-lg font-medium text-gray-500 hover:text-black transition duration-300", href="gallery.html") Gallery
                                    li(class="mb-2.5")
                                        a(class="inline-block text-lg font-medium text-gray-500 hover:text-black transition duration-300", href="documentation.html") Documentation
                                    li(class="mb-2.5")
                                        a(class="inline-block text-lg font-medium text-gray-500 hover:text-black transition duration-300", href="contact.html") Contact

    //- PDF Modal
    div#pdf-modal.hidden.fixed.inset-0.z-50.flex.items-center.justify-center.p-4
        div#pdf-content(
            class="bg-white w-full max-w-5xl h-[80vh] rounded-xl shadow-lg overflow-hidden relative"
            onclick="event.stopPropagation()"
        )
            button#close-pdf-modal(
            class="absolute top-3 right-4 text-black text-2xl font-bold hover:text-red-500"
            ) ×
            iframe#pdf-frame(
            class="w-full h-full"
            type="application/pdf"
            )



script.
  const paperPaths = {
    paper1: "template-assets/pdf/Synthetic_Image_Data_for_Deep_Learning.pdf",
    paper2: "template-assets/pdf/Domain_randomization_for_transferring_deep_neural_networks_from_simulation_to_the_real_world.pdf",
    // Add more papers here
  };

  const modal = document.getElementById("pdf-modal");
  const frame = document.getElementById("pdf-frame");

  // Open modal
  document.querySelectorAll(".view-paper-button").forEach(button => {
    button.addEventListener("click", () => {
      const paperId = button.dataset.paperId;
      const pdfPath = paperPaths[paperId];

      if (pdfPath) {
        frame.src = pdfPath;
        modal.classList.remove("hidden");
      }
    });
  });

  // Close when clicking the close button
  document.getElementById("close-pdf-modal").addEventListener("click", () => {
    modal.classList.add("hidden");
    frame.src = "";
  });

  // Close when clicking the backdrop (anywhere outside the content)
  document.getElementById("pdf-modal").addEventListener("click", () => {
    modal.classList.add("hidden");
    frame.src = "";
  });